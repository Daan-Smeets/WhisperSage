{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "d20ffd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chipwhisperer as cw  \n",
    "\n",
    "scope = cw.scope()\n",
    "target = cw.target(scope, cw.targets.SimpleSerial) #cw.targets.SimpleSerial can be omitted\n",
    "scope.default_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "95547282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class IncrementalStats:\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.mean = None  # Start with None to handle dynamic sizes\n",
    "        self.sum_sq = None\n",
    "        self.variance = None\n",
    "\n",
    "    def add_trace(self, trace):\n",
    "        trace_length = len(trace)\n",
    "        if self.mean is None:\n",
    "            # Initialize the arrays dynamically based on the first trace length\n",
    "            self.mean = np.zeros(trace_length)\n",
    "            self.sum_sq = np.zeros(trace_length)\n",
    "            self.variance = np.zeros(trace_length)\n",
    "        elif trace_length != len(self.mean):\n",
    "            # Adjust the existing arrays to accommodate a trace of new length\n",
    "            # This case handles if the new trace length is shorter or longer\n",
    "            if trace_length > len(self.mean):\n",
    "                # Extend arrays with zeros if new trace is longer\n",
    "                extension = np.zeros(trace_length - len(self.mean))\n",
    "                self.mean = np.concatenate((self.mean, extension))\n",
    "                self.sum_sq = np.concatenate((self.sum_sq, extension))\n",
    "                self.variance = np.concatenate((self.variance, extension))\n",
    "            else:\n",
    "                # If new trace is shorter, use slicing to adjust\n",
    "                self.mean = self.mean[:trace_length]\n",
    "                self.sum_sq = self.sum_sq[:trace_length]\n",
    "                self.variance = self.variance[:trace_length]\n",
    "\n",
    "        self.n += 1\n",
    "        delta = trace - self.mean\n",
    "        self.mean += delta / self.n\n",
    "        self.sum_sq += trace**2\n",
    "        if self.n > 1:\n",
    "            self.variance = (self.sum_sq - self.n * self.mean**2) / (self.n - 1)\n",
    "        else:\n",
    "            self.variance = np.zeros_like(self.variance)  # Variance is undefined for n=1\n",
    "\n",
    "    def get_stats(self):\n",
    "        return self.mean, self.variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7938bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import struct\n",
    "import scipy # 1.13.0\n",
    "import numpy as np #1.26.4\n",
    "import json\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "def mean(data):\n",
    "    \"\"\"\n",
    "        Calculate the mean of the input data along the specified axis.\n",
    "        \n",
    "        Parameters:\n",
    "            data (array-like): Input data for which the mean is calculated.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Mean of the input data.\n",
    "    \"\"\"\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "def variance(data):\n",
    "    \"\"\"\n",
    "        Calculate the variance of the input data along the specified axis.\n",
    "        \n",
    "        Parameters:\n",
    "            data (array-like): Input data for which the variance is calculated.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Variance of the input data.\n",
    "    \"\"\"\n",
    "    return np.var(data, axis=0, ddof=1)\n",
    "\n",
    "\n",
    "def ttest_ind_2d(sample1, sample2):\n",
    "    \"\"\"\n",
    "        Perform a 2D t-test on two independent samples.\n",
    "        \n",
    "        Parameters:\n",
    "            sample1 (array-like): First sample data.\n",
    "            sample2 (array-like): Second sample data.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: T-statistic values.\n",
    "    \"\"\"\n",
    "    sample1 = np.array(sample1)\n",
    "    sample2 = np.array(sample2)\n",
    "    \n",
    "    # Find the minimum number of columns in both samples\n",
    "    min_columns = min(sample1.shape[1], sample2.shape[1])\n",
    "    \n",
    "    # Resize both samples to the smallest number of columns\n",
    "    sample1 = sample1[:, :min_columns]\n",
    "    sample2 = sample2[:, :min_columns]\n",
    "    \n",
    "    \n",
    "    mean1, mean2 = mean(sample1), mean(sample2)\n",
    "    var1, var2 = variance(sample1), variance(sample2)\n",
    "    n1, n2 = sample1.shape[0], sample2.shape[0]\n",
    "\n",
    "    pooled_se = np.sqrt(var1/n1 + var2/n2)\n",
    "    \n",
    "    t_stat = (mean1 - mean2) / pooled_se\n",
    "    return t_stat\n",
    "\n",
    "\n",
    "def reset_target(scope):\n",
    "    \"\"\"\n",
    "    Reset the target device by toggling the reset pin.\n",
    "    \n",
    "    Parameters:\n",
    "        scope: ChipWhisperer scope object to control the hardware.\n",
    "    \"\"\"\n",
    "    scope.io.nrst = 'low'\n",
    "    time.sleep(0.05)\n",
    "    scope.io.nrst = 'high'\n",
    "    time.sleep(0.05)\n",
    "\n",
    "def cap_pass_trace(num, nr, arr, i):\n",
    "    \"\"\"\n",
    "    Capture and pass a trace from the target device.\n",
    "    \n",
    "    Parameters:\n",
    "        num (int): Number to write to the target.\n",
    "        nr (int): Number of repetitions.\n",
    "        arr (list): Array to store the captured trace.\n",
    "        i (int): Index for storing the trace.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Captured trace data.\n",
    "    \n",
    "    Raises:\n",
    "        Exception: If a timeout occurs during acquisition.\n",
    "    \"\"\"\n",
    "    scope.arm()\n",
    "    target.write(num)\n",
    "    if not scope.capture():\n",
    "        trace = scope.get_last_trace()\n",
    "        arr[i][:] = trace\n",
    "        if nr == 1:\n",
    "            plt.plot(trace[0:100])\n",
    "        return trace\n",
    "    else:\n",
    "        print('Timeout happened during acquisition')\n",
    "        raise Exception(\"Error occurred in function_deep\")\n",
    "        \n",
    "        \n",
    "\n",
    "def send_string(s):\n",
    "    \"\"\"\n",
    "    Send a string to the target device, character by character.\n",
    "    \n",
    "    Parameters:\n",
    "        s (str): String to send to the target.\n",
    "    \"\"\"\n",
    "    for c in s:\n",
    "        target.write(c.encode())\n",
    "        \n",
    "def parser(flag_string, max_no_traces, arr_trace_ct, inc_stats_ct, nr):\n",
    "    \"\"\"\n",
    "    Parse and capture traces from the target device.\n",
    "    \n",
    "    Parameters:\n",
    "        flag_string (str): String containing flags for the target.\n",
    "        max_no_traces (int): Maximum number of traces to capture.\n",
    "        arr (list): Array to store the captured traces.\n",
    "        inc_stats: Incremental statistics object to update with new traces.\n",
    "        nr (int): Number of repetitions.\n",
    "    \"\"\"\n",
    "    send_string(f\"{flag_string}\")\n",
    "    \n",
    "    recv_byte = 's'; #start\n",
    "    for i in range (max_no_traces):\n",
    "        if (recv_byte == 's' or recv_byte == 'd'):  # Start ('s') or Done ('d') with the current trace\n",
    "            trace = cap_pass_trace(b'g', nr, arr_trace_ct, i)\n",
    "            inc_stats_ct.add_trace(trace)\n",
    "            time.sleep(0.1)\n",
    "            recv_byte = target.read(1)\n",
    "            while (recv_byte == \"\"):  #Different implementations have different processing times\n",
    "                time.sleep(0.1)\n",
    "                recv_byte = target.read(1)\n",
    "            if (i % 50 == 0):\n",
    "                print(f\"Recv byte: {recv_byte}\")\n",
    "    target.write(b'e')\n",
    "\n",
    "    \n",
    "def run_program(inc_stats_same_ct, inc_stats_random_ct, inc_stats, run_i, max_no_traces, flag_string, samples_max, samples_left, total_trace_segments, traces_per_seg, output_directory):\n",
    "    \"\"\"\n",
    "    Run the main program for capturing and analyzing traces from the target device.\n",
    "    \n",
    "    Parameters:\n",
    "        inc_stats_same_ct: Incremental statistics object for same ciphertext traces.\n",
    "        inc_stats_random_ct: Incremental statistics object for random ciphertext traces.\n",
    "        inc_stats: Incremental statistics object for the combined statistics.\n",
    "        run_i (int): Current run index.\n",
    "        max_no_traces (int): Maximum number of traces to capture.\n",
    "        flag_string (str): String containing flags for the target.\n",
    "        samples_max (int): Maximum number of samples per trace.\n",
    "        samples_left (int): Number of samples left to capture.\n",
    "        total_trace_segments (int): Total number of trace segments.\n",
    "        traces_per_seg (int): Number of traces per segment.\n",
    "        output_directory (str): Output directory name for saving trace data.\n",
    "    \"\"\"\n",
    "    run_offset = run_i * scope.adc.samples\n",
    "    scope.adc.offset = run_offset\n",
    "        \n",
    "    scope.adc.samples = min(scope.adc.samples, samples_left)\n",
    "\n",
    "    arr_trace_same_ct = [[0 for i in range(scope.adc.samples)] for j in range(max_no_traces)]\n",
    "    arr_trace_random_ct = [[0 for i in range(scope.adc.samples)] for j in range(max_no_traces)]\n",
    "\n",
    "    parser(f\"{flag_string}\", max_no_traces, arr_trace_same_ct, inc_stats_same_ct, run_i)\n",
    "    print(f\"Finished Same CT Test Segment: {run_i}\")\n",
    "    \n",
    "    parser(f\"{flag_string}fw\", max_no_traces, arr_trace_random_ct, inc_stats_random_ct, run_i)\n",
    "    print(f\"Finished Random CT Test Segment: {run_i}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # Assume stats1 and stats2 are instances of IncrementalStats for group 1 and group 2\n",
    "    mean1, var1 = inc_stats_same_ct.get_stats()\n",
    "    mean2, var2 = inc_stats_random_ct.get_stats()\n",
    "    n1 = inc_stats_same_ct.n\n",
    "    n2 = inc_stats_random_ct.n\n",
    "\n",
    "    # Compute the t-statistic for each point\n",
    "    pooled_se = np.sqrt(var1 / n1 + var2 / n2)\n",
    "    inc_values = (mean1 - mean2) / pooled_se\n",
    "    \n",
    "    inc_stats[run_offset:run_offset+scope.adc.samples] = inc_values\n",
    "    \n",
    "    count = 0\n",
    "    for stat in inc_stats[run_offset:run_offset+scope.adc.samples]:\n",
    "        if abs(stat) > 4.5:\n",
    "#             print(stat)\n",
    "            count += 1\n",
    "    print(f\"count inc seg {run_i}: {count}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # Create the initial directory, the loop creates the sub-directories\n",
    "    os.makedirs(f\"{output_directory}/{max_no_traces}_traces_{samples_max}_samples\", exist_ok=True)\n",
    "\n",
    "    for trace_seg_i in range(total_trace_segments):\n",
    "        os.makedirs(f'{output_directory}/{max_no_traces}_traces_{samples_max}_samples/{run_i}_run_seg/{trace_seg_i}_trace_seg', exist_ok=True)\n",
    "\n",
    "        trace_offset = trace_seg_i * traces_per_seg\n",
    "        \n",
    "        tmp_arr_same_ct = arr_trace_same_ct[trace_offset:trace_offset+traces_per_seg]\n",
    "        scipy.io.savemat(f\"{output_directory}/{max_no_traces}_traces_{samples_max}_samples/{run_i}_run_seg/{trace_seg_i}_trace_seg/same_ct_test_{samples_max}_{run_i}_{trace_seg_i}.mat\", {\"same_ct_test\": tmp_arr_same_ct})\n",
    "\n",
    "        tmp_arr_random_ct = arr_trace_random_ct[trace_offset:trace_offset+traces_per_seg]\n",
    "        scipy.io.savemat(f\"{output_directory}/{max_no_traces}_traces_{samples_max}_samples/{run_i}_run_seg/{trace_seg_i}_trace_seg/random_ct_test_{samples_max}_{run_i}_{trace_seg_i}.mat\", {\"random_ct_test\": tmp_arr_random_ct})\n",
    "\n",
    "        \n",
    "    scipy.io.savemat(f\"{output_directory}/{max_no_traces}_traces_{samples_max}_samples/tstats_{run_i}_{samples_max}.mat\", {\"tstats\": inc_values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc72ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main test function to set parameters and run the trace capture and analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    #----------BEGIN FLAGS TO SET----------#\n",
    "    max_no_traces = 1000\n",
    "    total_trace_segments = 1\n",
    "    scope.adc.samples = 24400\n",
    "    flags = \"l\"\n",
    "    output_directory = \"traces_kyber_masked_sk\"\n",
    "    #----------END FLAGS TO SET------------#\n",
    "    \n",
    "    traces_per_seg = max_no_traces // total_trace_segments\n",
    "    samples_max = scope.adc.samples\n",
    "    scope.adc.offset = 0\n",
    "    arr_offset = scope.adc.offset\n",
    "\n",
    "    reset_target(scope)\n",
    "    time.sleep(4)\n",
    "    target.flush()\n",
    "    \n",
    "    flag_string = \"\"\n",
    "    \n",
    "    for f in flags:\n",
    "        flag_string += f\"f{f}\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Run it once to determine the trig_count\n",
    "    inc_stats_trig = IncrementalStats()\n",
    "    arr_0 = [[0 for i in range(samples_max)] for j in range(max_no_traces)]\n",
    "    parser(f\"{flag_string}\", 1, arr_0, inc_stats_trig, 0)\n",
    "    \n",
    "    nr_runs_full_cap = (scope.adc.trig_count + samples_max - 1) // samples_max  # Round up without math lib\n",
    "    print(\"Total trigger count for the capture: \" + str(scope.adc.trig_count))\n",
    "    print(\"Total number of runs that will be performed: \" + str(nr_runs_full_cap))\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    inc_stats = [0 for i in range(scope.adc.trig_count)]\n",
    "     \n",
    "    run_i = 0\n",
    "    samples_left = scope.adc.trig_count   # Init samples_left as the total number of triggers\n",
    "    \n",
    "    while (run_i < nr_runs_full_cap):\n",
    "        inc_stats_same_ct = IncrementalStats()\n",
    "        inc_stats_random_ct = IncrementalStats()\n",
    "        run_program(inc_stats_same_ct, inc_stats_random_ct, inc_stats, run_i, max_no_traces, flag_string, samples_max, samples_left, total_trace_segments, traces_per_seg, output_directory)\n",
    "        samples_left -= samples_max\n",
    "        run_i += 1\n",
    "        \n",
    "    \n",
    "    target.write(b'm')\n",
    "    plt.show()\n",
    "    \n",
    "    count = 0\n",
    "    for stat in inc_stats:\n",
    "        if abs(stat) > 4.5:\n",
    "            count += 1\n",
    "    print(f\"count inc: {count}\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
